{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction to our first task: 'Dogs vs Cats'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"/home/paperspace/data/dogscats/\"\n",
    "sz=224\n",
    "batch_size=64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras.applications import ResNet50\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras import backend as K\n",
    "from keras.applications.resnet50 import preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_dir = f'{PATH}train'\n",
    "validation_data_dir = f'{PATH}valid'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather then creating a Data object, first need to create Data Generator, to define how we generate the data: what kind of data augmentation and data normalization we'd like to do.\n",
    "\n",
    "We kinda need to not a little bit of what is expected for resnet50.\n",
    "\n",
    "Generally speaking copy&pasting Keras code from the internet is a good way to be sure you've got the right stuff to make that work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 23000 images belonging to 2 classes.\n",
      "Found 2000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_datagen = ImageDataGenerator(\n",
    "                                   rescale=1. / 255,\n",
    "                                   #preprocessing_function=preprocess_input,\n",
    "                                   shear_range=0.2,\n",
    "                                   zoom_range=0.2,\n",
    "                                   horizontal_flip=True)\n",
    "\n",
    "# It's up to you to create the generator that doesn't have data augmentation\n",
    "test_datagen = ImageDataGenerator(\n",
    "                                 rescale=1. / 255\n",
    "                                 #preprocessing_function=preprocess_input\n",
    "                                    )\n",
    "\n",
    "# We then create a data generator from that, by taking that data generator\n",
    "# by looking from a directory\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "                                                    target_size=(sz,sz),\n",
    "                                                    batch_size=batch_size,\n",
    "                                                    class_mode='binary')\n",
    "\n",
    "# You have to do the same for the validation set\n",
    "validation_generator = \\\n",
    "    test_datagen.flow_from_directory(validation_data_dir,\n",
    "                                     shuffle=False,\n",
    "                                     target_size=(sz, sz),\n",
    "                                     batch_size=batch_size,\n",
    "                                     class_mode='binary')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I use ResNet50 cause Keras doesn't have ResNet34 unfortunately\n",
    "\n",
    "You have to construct a model on top of base model by hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 7.84 s, sys: 616 ms, total: 8.46 s\n",
      "Wall time: 8.25 s\n"
     ]
    }
   ],
   "source": [
    "%time base_model = ResNet50(weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base model\n",
    "x = base_model.output\n",
    "# layers on top of that\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(1024, activation='relu')(x)\n",
    "predictions = Dense(1, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no concept of automatically freezing things or API for that, so you have to look through the layers you want to freeze\n",
    "\n",
    "In Keras there is a concept we don't have in fastai or Pytorch of compiling a model. With fastai we know what loss is the right loss to use. You can always overwrite it, but for particular model we give you good defaults"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Passing in `train_generator` and `validation_generator`\n",
    "* For some reason Keras also expects you to tell it how many batches there are per epoch.\n",
    "    * The number of batches is equal to the size of generator divided by the batch size\n",
    "* You can tell it how many epochs\n",
    "* Just like fastai you can tell it how many processes(`workers`) to use for preprocessing\n",
    "    * Unlike fastai the default in Keras is not to use any. So to get good speed you gonna make sure to include this\n",
    "    \n",
    "That's basically enough to start fintuning the last layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "359/359 [==============================] - 200s 558ms/step - loss: 0.2376 - acc: 0.9346 - val_loss: 1.7505 - val_acc: 0.5040\n",
      "Epoch 2/3\n",
      "359/359 [==============================] - 195s 542ms/step - loss: 0.1040 - acc: 0.9627 - val_loss: 1.7953 - val_acc: 0.5040\n",
      "Epoch 3/3\n",
      "359/359 [==============================] - 195s 542ms/step - loss: 0.0834 - acc: 0.9697 - val_loss: 2.2627 - val_acc: 0.5040\n",
      "CPU times: user 19min 36s, sys: 41.3 s, total: 20min 18s\n",
      "Wall time: 9min 49s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe3ab61a0b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(train_generator,\n",
    "                    train_generator.n // batch_size,\n",
    "                    epochs=3,\n",
    "                    workers=4,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is not concept of layer goups or differential learning rates or partial unfreezing.\n",
    "\n",
    "So I have to print out all of the layers and decide manually how many I want to fine-tune. So I decide to fine-tune everything from layer `140` onwards.\n",
    "\n",
    "After you change this you have to recompile the model, and then I run another step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_at = 140\n",
    "for layer in model.layers[:split_at]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[split_at:]:\n",
    "    layer.trainable = True\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "359/359 [==============================] - 240s 669ms/step - loss: 0.0920 - acc: 0.9704 - val_loss: 0.7268 - val_acc: 0.5040\n",
      "CPU times: user 7min 4s, sys: 25.2 s, total: 7min 30s\n",
      "Wall time: 4min 1s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe329b48da0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "model.fit_generator(train_generator,\n",
    "                    train_generator.n // batch_size,\n",
    "                    epochs=1, workers=3,\n",
    "                    validation_data=validation_generator,\n",
    "                    validation_steps=validation_generator.n // batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
