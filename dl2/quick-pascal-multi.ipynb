{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "import json, pdb\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects\n",
    "#torch.cuda.set_device(0)\n",
    "\n",
    "#torch.backends.cudnn.benchmark=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/pascal')\n",
    "trn_j = json.load((PATH / 'pascal_train2007.json').open())\n",
    "IMAGES,ANNOTATIONS,CATEGORIES = ['images', 'annotations', 'categories']\n",
    "FILE_NAME,ID,IMG_ID,CAT_ID,BBOX = 'file_name','id','image_id','category_id','bbox'\n",
    "\n",
    "cats = dict((o[ID], o['name']) for o in trn_j[CATEGORIES])\n",
    "trn_fns = dict((o[ID], o[FILE_NAME]) for o in trn_j[IMAGES])\n",
    "trn_ids = [o[ID] for o in trn_j[IMAGES]]\n",
    "\n",
    "JPEGS = 'VOCdevkit/VOC2007/JPEGImages'\n",
    "IMG_PATH = PATH/JPEGS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions for exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hw_bb(bb): return np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n",
    "\n",
    "def get_trn_anno():\n",
    "    trn_anno = collections.defaultdict(lambda:[])\n",
    "    for o in trn_j[ANNOTATIONS]:\n",
    "        if not o['ignore']:\n",
    "            bb = o[BBOX]\n",
    "            bb = hw_bb(bb)\n",
    "            trn_anno[o[IMG_ID]].append((bb,o[CAT_ID]))\n",
    "    return trn_anno\n",
    "\n",
    "trn_anno = get_trn_anno()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1]+1,a[2]-a[0]+1])\n",
    "\n",
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.set_xticks(np.linspace(0, 224, 8))\n",
    "    ax.set_yticks(np.linspace(0, 224, 8))\n",
    "    ax.grid()\n",
    "    ax.set_yticklabels([])\n",
    "    ax.set_xticklabels([])\n",
    "    return ax\n",
    "\n",
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(\n",
    "        linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def draw_rect(ax, b, color='white'):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False, edgecolor=color, lw=2))\n",
    "    draw_outline(patch, 4)\n",
    "\n",
    "def draw_text(ax, xy, txt, sz=14, color='white'):\n",
    "    text = ax.text(*xy, txt,\n",
    "        verticalalignment='top', color=color, fontsize=sz, weight='bold')\n",
    "    draw_outline(text, 1)\n",
    "    \n",
    "def draw_im(im, ann):\n",
    "    ax = show_img(im, figsize=(16,8))\n",
    "    for b,c in ann:\n",
    "        b = bb_hw(b)\n",
    "        draw_rect(ax, b)\n",
    "        draw_text(ax, b[:2], cats[c], sz=16)\n",
    "\n",
    "def draw_idx(i):\n",
    "    im_a = trn_anno[i]\n",
    "    im = open_image(IMG_PATH/trn_fns[i])\n",
    "    draw_im(im, im_a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "MC_CSV = PATH/'tmp/mc.csv'\n",
    "mc = [set([cats[p[1]] for p in trn_anno[o]]) for o in trn_ids]\n",
    "mcs = [' '.join(str(p) for p in o) for o in mc]\n",
    "df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids], 'clas': mcs}, columns=['fn','clas'])\n",
    "df.to_csv(MC_CSV, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model=resnet34\n",
    "sz=224\n",
    "bs=64\n",
    "\n",
    "tfms = tfms_from_model(f_model, sz, crop_type=CropType.NO)\n",
    "md = ImageClassifierData.from_csv(PATH, JPEGS, MC_CSV, tfms=tfms)\n",
    "\n",
    "learn = ConvLearner.pretrained(f_model, md)\n",
    "learn.opt_fn = optim.Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-2\n",
    "learn.fit(lr, 1, cycle_len=3, use_clr=(32,5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.array([lr/100, lr/10, lr])\n",
    "learn.freeze_to(-2)\n",
    "learn.fit(lrs/10, 1, cycle_len=5, use_clr=(32,5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = learn.predict()\n",
    "x,_ = next(iter(md.val_dl))\n",
    "x = to_np(x)\n",
    "\n",
    "fig, axes = plt.subplots(3, 4, figsize=(12, 8))\n",
    "for i,ax in enumerate(axes.flat):\n",
    "    ima=md.val_ds.denorm(x)[i]\n",
    "    ya = np.nonzero(y[i]>0.4)[0]\n",
    "    b = '\\n'.join(md.classes[o] for o in ya)\n",
    "    ax = show_img(ima, ax=ax)\n",
    "    draw_text(ax, (0,0), b)\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bbox per cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define model and augmentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some new functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Custom datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Many custom functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# More anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create anchors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Focal loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NMS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,_ = next(iter(md.val_dl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 3, 224, 224])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs,nf,gx,gy = x.size()\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 224, 224, 3])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.permute(0,2,3,1)\n",
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.3954\n",
       " 0.2387\n",
       " 0.6008\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       " 0.3954\n",
       " 0.2387\n",
       " 0.6008\n",
       "[torch.FloatTensor of size 3]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = x.contiguous()\n",
    "x[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 50176, 3])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.view(bs,-1,nf//1).size()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "228px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
