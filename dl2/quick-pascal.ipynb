{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "\n",
    "from pathlib import Path\n",
    "import json\n",
    "from PIL import ImageDraw, ImageFont\n",
    "from matplotlib import patches, patheffects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bb_hw(a): return np.array([a[1],a[0],a[3]-a[1],a[2]-a[0]])\n",
    "\n",
    "def show_img(im, figsize=None, ax=None):\n",
    "    if not ax: fig,ax = plt.subplots(figsize=figsize)\n",
    "    ax.imshow(im)\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "    return ax\n",
    "\n",
    "def draw_outline(o, lw):\n",
    "    o.set_path_effects([patheffects.Stroke(\n",
    "        linewidth=lw, foreground='black'), patheffects.Normal()])\n",
    "\n",
    "def draw_rect(ax, b):\n",
    "    patch = ax.add_patch(patches.Rectangle(b[:2], *b[-2:], fill=False,\n",
    "                                        edgecolor='white', lw=2))\n",
    "    draw_outline(patch, 4)\n",
    "\n",
    "def draw_text(ax, xy, txt, sz=14):\n",
    "    text = ax.text(*xy, txt, verticalalignment='top',\n",
    "                   color='white', fontsize=sz, weight='bold')\n",
    "    draw_outline(text, 1)\n",
    "    \n",
    "def draw_im(im, ann):\n",
    "    ax = show_img(im, figsize=(16,8))\n",
    "    for b,c in ann:\n",
    "        b = bb_hw(b)\n",
    "        draw_rect(ax, b)\n",
    "        draw_text(ax, b[:2], cats[c], sz=16)\n",
    "\n",
    "def draw_idx(i):\n",
    "    im_a = trn_anno[i]    \n",
    "    im = open_image(IMG_PATH/trn_fns[i])\n",
    "    print(im.shape)\n",
    "    draw_im(im, im_a)\n",
    "    \n",
    "def get_lrg(b):\n",
    "    if not b: raise Exeption()\n",
    "    b = sorted(b, key=lambda x: np.product(x[0][-2:]-x[0][:2]), reverse=True)\n",
    "    return b[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/pascal')\n",
    "\n",
    "trn_j = json.load((PATH / 'pascal_train2007.json').open())\n",
    "IMAGES, ANNOTATIONS, CATEGORIES = ['images', 'annotations', 'categories']\n",
    "FILE_NAME,ID,IMG_ID,CAT_ID,BBOX = 'file_name','id','image_id','category_id','bbox'\n",
    "cats = {o[ID]: o['name'] for o in trn_j[CATEGORIES]}\n",
    "trn_fns = dict((o[ID], o[FILE_NAME]) for o in trn_j[IMAGES])\n",
    "trn_ids = [o[ID] for o in trn_j[IMAGES]]\n",
    "\n",
    "JPEGS = 'VOCdevkit/VOC2007/JPEGImages'\n",
    "IMG_PATH = PATH/JPEGS\n",
    "\n",
    "trn_anno = collections.defaultdict(list)\n",
    "for o in trn_j[ANNOTATIONS]:\n",
    "    if not o['ignore']:\n",
    "        bb = o[BBOX]\n",
    "        bb = np.array([bb[1], bb[0], bb[3]+bb[1]-1, bb[2]+bb[0]-1])\n",
    "        trn_anno[o[IMG_ID]].append((bb, o[CAT_ID]))\n",
    "        \n",
    "trn_lrg_anno = {a: get_lrg(b) for a,b in trn_anno.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fn</th>\n",
       "      <th>cat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000012.jpg</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000017.jpg</td>\n",
       "      <td>horse</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000023.jpg</td>\n",
       "      <td>person</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000026.jpg</td>\n",
       "      <td>car</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000032.jpg</td>\n",
       "      <td>aeroplane</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           fn        cat\n",
       "0  000012.jpg        car\n",
       "1  000017.jpg      horse\n",
       "2  000023.jpg     person\n",
       "3  000026.jpg        car\n",
       "4  000032.jpg  aeroplane"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(PATH/'tmp').mkdir(exist_ok=True)\n",
    "CSV = PATH/'tmp/lrg.csv'\n",
    "df = pd.DataFrame({'fn': [trn_fns[o] for o in trn_ids],\n",
    "                   'cat': [cats[trn_lrg_anno[o][1]] for o in trn_ids]},\n",
    "                   columns=['fn','cat'])\n",
    "df.to_csv(CSV, index=False)\n",
    "pd.read_csv(CSV).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model = resnet34\n",
    "sz=224\n",
    "bs=64\n",
    "\n",
    "tfms = tfms_from_model(f_model, sz, aug_tfms=transforms_side_on, crop_type=CropType.NO)\n",
    "md = ImageClassifierData.from_csv(PATH, JPEGS, CSV, tfms=tfms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=next(iter(md.val_dl))\n",
    "#show_img(md.val_ds.denorm(to_np(x))[0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4378978bfebf470298982e2ec1bbd9fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                 \n",
      "    0      1.302087   0.668427   0.809495  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6684272289276123, 0.8094951957464218]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn = ConvLearner.pretrained(f_model, md, metrics=[accuracy])\n",
    "learn.opt_fn = optim.Adam\n",
    "lr = 2e-2\n",
    "learn.fit(lr, 1, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "288cbc70c39142669b39386a5eb48b13",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.363757   0.61983    0.821064  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.6198300942778587, 0.8210637047886848]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lrs = np.array([lr/1000,lr/100,lr])\n",
    "learn.freeze_to(-2)\n",
    "learn.fit(lrs/5, 1, cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f13c2e92cb184ab6be5bc87fbf0650ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=2), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                  \n",
      "    0      0.652215   0.562579   0.822566  \n",
      "    1      0.448812   0.576637   0.824519                  \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.5766368880867958, 0.8245192319154739]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learn.unfreeze()\n",
    "learn.fit(lrs/5, 1, cycle_len=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('class_one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 11,  2, 14, 14,  6, 13,  8,  2, 16])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "probs = F.softmax(predict_batch(learn.model, x), -1)\n",
    "x,preds = to_np(x),to_np(probs)\n",
    "preds = np.argmax(preds, -1)\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.4912e+01 -5.8179e+00 -1.2194e+01  ...  -1.3608e+01 -1.3405e+01 -1.3641e+01\n",
       "-1.1735e+01 -9.0272e+00 -1.3055e+01  ...  -1.6911e+00 -1.3717e+01 -9.5481e+00\n",
       "-8.4287e+00 -1.2785e+01 -1.7634e-02  ...  -1.4863e+01 -1.3429e+01 -1.3263e+01\n",
       "                ...                   ⋱                   ...                \n",
       "-1.2520e+01 -9.3879e+00 -1.3070e+01  ...  -4.2500e+00 -1.2885e+01 -1.1605e+01\n",
       "-1.3474e+01 -1.1209e+01 -1.2944e+01  ...  -7.4971e+00 -1.2352e+01 -1.1298e+01\n",
       "-7.4638e+00 -1.0668e+01 -1.0699e+01  ...  -1.2035e+01 -7.9204e+00 -8.9310e+00\n",
       "[torch.cuda.FloatTensor of size 64x20 (GPU 0)]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_batch(learn.model, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-1.4912e+01 -5.8179e+00 -1.2194e+01  ...  -1.3608e+01 -1.3405e+01 -1.3641e+01\n",
       "-1.1735e+01 -9.0272e+00 -1.3055e+01  ...  -1.6911e+00 -1.3717e+01 -9.5481e+00\n",
       "-8.4287e+00 -1.2785e+01 -1.7634e-02  ...  -1.4863e+01 -1.3429e+01 -1.3263e+01\n",
       "                ...                   ⋱                   ...                \n",
       "-1.2520e+01 -9.3879e+00 -1.3070e+01  ...  -4.2500e+00 -1.2885e+01 -1.1605e+01\n",
       "-1.3474e+01 -1.1209e+01 -1.2944e+01  ...  -7.4971e+00 -1.2352e+01 -1.1298e+01\n",
       "-7.4638e+00 -1.0668e+01 -1.0699e+01  ...  -1.2035e+01 -7.9204e+00 -8.9310e+00\n",
       "[torch.cuda.FloatTensor of size 64x20 (GPU 0)]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y = next(iter(md.val_dl))\n",
    "learn.model(VV(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14, 11,  2, 14, 14,  6, 13,  8,  2, 16, 15,  6, 17,  7, 12,  0, 14, 14,  7, 19,  1,  8, 14, 13, 14,\n",
       "       14, 14,  5,  9, 18, 13,  0,  2,  6, 18, 11, 12,  6,  0, 10,  6, 13, 12, 14,  3, 13, 14,  7, 12, 13,\n",
       "       12, 14, 13,  2, 14, 11,  6,  0,  2,  2,  2,  7, 14,  9])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(to_np(F.softmax(predict_batch(learn.model, x))), -1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
